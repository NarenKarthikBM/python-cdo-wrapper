{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00264e52",
   "metadata": {},
   "source": [
    "# python-cdo-wrapper v1.0.0 Demo Notebook\n",
    "\n",
    "**Complete demonstration of the new Django ORM-inspired query API**\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates all major features introduced in **python-cdo-wrapper v1.0.0**, a complete architectural overhaul that brings a Django-inspired QuerySet pattern to climate data processing with CDO (Climate Data Operators).\n",
    "\n",
    "### Key Features Demonstrated\n",
    "\n",
    "- üîó **Lazy Query API** - Build pipelines with chainable methods, execute when ready\n",
    "- üîç **Query Introspection** - Inspect CDO commands before execution\n",
    "- üå≥ **Query Branching** - Clone queries for multiple analyses\n",
    "- ‚ú® **F() Function** - One-liner anomaly calculations (Django F-expression pattern)\n",
    "- üìä **150+ Operators** - Selection, statistics, arithmetic, interpolation\n",
    "- üì¶ **Structured Results** - Type-safe dataclasses for info commands\n",
    "- üîÑ **Backward Compatible** - v0.x API still works!\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- **Python**: >= 3.9\n",
    "- **CDO**: >= 1.9.8\n",
    "- **python-cdo-wrapper**: >= 1.0.0\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Install python-cdo-wrapper\n",
    "pip install python-cdo-wrapper>=1.0.0\n",
    "\n",
    "# Install CDO if needed\n",
    "# macOS: brew install cdo\n",
    "# Linux: sudo apt install cdo\n",
    "# Conda: conda install -c conda-forge cdo\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import required libraries and check environment.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Import python-cdo-wrapper v1.0.0 API\n",
    "from python_cdo_wrapper import CDO, F\n",
    "from python_cdo_wrapper.types import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check CDO installation and version.\n",
    "Verifies that CDO >= 1.9.8 is available for F() function support.\n",
    "\"\"\"\n",
    "\n",
    "from python_cdo_wrapper.utils import get_cdo_version\n",
    "\n",
    "try:\n",
    "    version = get_cdo_version()\n",
    "    print(f\"‚úÖ CDO installed: {version}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå CDO not found: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4285f9e7",
   "metadata": {},
   "source": [
    "### Create Sample Climate Data\n",
    "\n",
    "We'll generate synthetic NetCDF files with realistic climate data for demonstration purposes:\n",
    "\n",
    "- **sample_data.nc** - 3 years of daily data (2020-2022)\n",
    "  - `tas`: Temperature on 4 pressure levels (1000, 850, 500, 250 hPa)\n",
    "  - `pr`: Precipitation (surface)\n",
    "  - Grid: 2¬∞ √ó 2¬∞ global coverage\n",
    "  \n",
    "- **climatology.nc** - Time mean for anomaly calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f441d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create synthetic climate data for demonstration.\n",
    "Generates realistic temperature and precipitation fields.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_sample_data(filename=\"sample_data.nc\"):\n",
    "    \"\"\"\n",
    "    Create synthetic climate data with spatial and temporal dimensions.\n",
    "\n",
    "    Returns:\n",
    "        xr.Dataset: The created dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Define dimensions\n",
    "    lon = np.arange(0, 360, 2)  # 180 longitude points (2¬∞ resolution)\n",
    "    lat = np.arange(-90, 91, 2)  # 91 latitude points (2¬∞ resolution)\n",
    "    time = xr.cftime_range(\n",
    "        start=\"2020-01-01\", periods=365 * 3, freq=\"D\"\n",
    "    )  # 3 years daily\n",
    "    level = [1000, 850, 500, 250]  # Pressure levels in hPa\n",
    "\n",
    "    # Create temperature field with realistic patterns\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "    # Base temperature: warm at equator, cold at poles\n",
    "    base_temp = 288 - 50 * np.abs(lat_grid) / 90\n",
    "\n",
    "    # Add seasonal cycle (10K amplitude)\n",
    "    seasonal_cycle = 10 * np.sin(2 * np.pi * np.arange(len(time)) / 365)\n",
    "\n",
    "    # Create 4D temperature array (time, level, lat, lon)\n",
    "    tas_data = np.zeros((len(time), len(level), len(lat), len(lon)))\n",
    "\n",
    "    for t in range(len(time)):\n",
    "        for lev_idx, lev in enumerate(level):\n",
    "            # Temperature decreases with altitude (standard lapse rate)\n",
    "            temp_at_level = base_temp - (1000 - lev) * 0.0065\n",
    "            # Add seasonal cycle\n",
    "            temp_at_level = temp_at_level + seasonal_cycle[t]\n",
    "            # Add random noise\n",
    "            temp_at_level = temp_at_level + np.random.randn(len(lat), len(lon)) * 2\n",
    "            tas_data[t, lev_idx, :, :] = temp_at_level\n",
    "\n",
    "    # Create xarray Dataset with CF conventions\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"tas\": (\n",
    "                [\"time\", \"level\", \"lat\", \"lon\"],\n",
    "                tas_data,\n",
    "                {\n",
    "                    \"long_name\": \"Near-Surface Air Temperature\",\n",
    "                    \"units\": \"K\",\n",
    "                    \"standard_name\": \"air_temperature\",\n",
    "                },\n",
    "            ),\n",
    "            \"pr\": (\n",
    "                [\"time\", \"lat\", \"lon\"],\n",
    "                np.random.exponential(3, (len(time), len(lat), len(lon))),\n",
    "                {\n",
    "                    \"long_name\": \"Precipitation\",\n",
    "                    \"units\": \"mm/day\",\n",
    "                    \"standard_name\": \"precipitation_flux\",\n",
    "                },\n",
    "            ),\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": time,\n",
    "            \"level\": level,\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "        },\n",
    "        attrs={\n",
    "            \"title\": \"Sample Climate Data\",\n",
    "            \"institution\": \"Python CDO Wrapper Demo\",\n",
    "            \"source\": \"Synthetic data for demonstration\",\n",
    "            \"Conventions\": \"CF-1.6\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save to NetCDF\n",
    "    ds.to_netcdf(filename)\n",
    "\n",
    "    print(f\"‚úÖ Created {filename}\")\n",
    "    print(\"   üìê Dimensions:\")\n",
    "    print(f\"      - Time:  {len(time)} timesteps (2020-01-01 to 2022-12-31)\")\n",
    "    print(f\"      - Level: {len(level)} pressure levels\")\n",
    "    print(f\"      - Lat:   {len(lat)} points (-90¬∞ to 90¬∞)\")\n",
    "    print(f\"      - Lon:   {len(lon)} points (0¬∞ to 358¬∞)\")\n",
    "    print(\"   üìä Variables:\")\n",
    "    print(\"      - tas: 4D temperature field (K)\")\n",
    "    print(\"      - pr:  3D precipitation field (mm/day)\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "# Create the sample dataset\n",
    "print(\"üîÑ Generating sample climate data...\\n\")\n",
    "sample_ds = create_sample_data(\"sample_data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31aa13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Django ORM-Style Query API\n",
    "\n",
    "The core innovation of v1.0.0 is the **Django QuerySet-inspired API**. Just like Django's ORM makes database queries intuitive and chainable, our query API makes CDO operations readable and composable.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Lazy Evaluation**: Operations are queued, not executed immediately\n",
    "- **Chainable Methods**: Build complex pipelines step by step\n",
    "- **Immutable Queries**: Each method returns a new query instance\n",
    "- **Terminal Operations**: Call `.compute()` to execute the pipeline\n",
    "\n",
    "This approach is inspired by Django's QuerySet pattern, which allows you to build complex database queries programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011168e",
   "metadata": {},
   "source": [
    "### 1.1 Basic Query Building (Lazy Evaluation)\n",
    "\n",
    "Build a query **without executing it** - just like Django QuerySets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrate lazy query building.\n",
    "Operations are added to the query but not executed until .compute() is called.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize CDO instance\n",
    "cdo = CDO()\n",
    "\n",
    "# Build a query pipeline - NO EXECUTION YET!\n",
    "query = (\n",
    "    cdo.query(\"sample_data.nc\")  # Start with input file\n",
    "    .select_var(\"tas\")  # Select temperature variable\n",
    "    .select_level(850)  # Select 850 hPa level\n",
    "    .select_year(2020, 2021)  # Select years 2020-2021\n",
    "    .year_mean()  # Compute annual means\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Query built successfully!\")\n",
    "print(f\"\\nüìã Query type: {type(query).__name__}\")\n",
    "print(f\"üîß Query object: {query}\")\n",
    "print(\"\\nüí° Note: No CDO command has been executed yet.\")\n",
    "print(\"   The query is lazy - it will only run when you call .compute()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6a8d0",
   "metadata": {},
   "source": [
    "### 1.2 Query Execution\n",
    "\n",
    "Call `.compute()` to execute the query and get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31714ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute the query and get results as xarray Dataset.\n",
    "\"\"\"\n",
    "\n",
    "# NOW execute the query\n",
    "result = query.compute()\n",
    "\n",
    "print(\"‚úÖ Query executed successfully!\")\n",
    "print(f\"\\nüì¶ Result type: {type(result)}\")\n",
    "print(f\"\\nüìê Dimensions: {dict(result.dims)}\")\n",
    "print(f\"üìä Variables: {list(result.data_vars)}\")\n",
    "print(f\"üìç Coordinates: {list(result.coords)}\")\n",
    "print(f\"\\nüå°Ô∏è  Mean temperature: {float(result.tas.mean().values):.2f} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ab8cb",
   "metadata": {},
   "source": [
    "### 1.3 Complex Query Chaining\n",
    "\n",
    "Chain multiple operations to build sophisticated analysis pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20348bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a complex multi-step analysis pipeline.\n",
    "This example extracts European winter temperature climatology.\n",
    "\"\"\"\n",
    "\n",
    "# Complex pipeline with multiple selections and aggregations\n",
    "complex_query = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")  # Select temperature\n",
    "    .select_level(1000)  # Surface pressure level\n",
    "    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)  # Europe bounding box\n",
    "    .select_season(\"DJF\")  # Winter (Dec-Jan-Feb)\n",
    "    .year_mean()  # Annual winter means\n",
    "    .field_mean()  # Spatial average\n",
    ")\n",
    "\n",
    "# Execute the pipeline\n",
    "europe_winter = complex_query.compute()\n",
    "\n",
    "print(\"‚úÖ European winter temperature (DJF) computed!\")\n",
    "print(f\"\\nüìê Result shape: {dict(europe_winter.dims)}\")\n",
    "print(\"üå°Ô∏è  Mean winter temperatures:\")\n",
    "for i, temp in enumerate(europe_winter.tas.values):\n",
    "    year = 2020 + i\n",
    "    print(f\"   {year}: {float(temp):.2f} K ({float(temp) - 273.15:.2f} ¬∞C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147357ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Query Introspection\n",
    "\n",
    "**Inspect queries before execution** - see exactly what CDO command will run!\n",
    "\n",
    "This is one of the most powerful features of v1.0.0. You can:\n",
    "- Preview the generated CDO command\n",
    "- Get a human-readable explanation\n",
    "- List all operations in the pipeline\n",
    "\n",
    "Perfect for debugging and understanding complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inspect a query to see what will be executed.\n",
    "Use this to debug and understand complex pipelines.\n",
    "\"\"\"\n",
    "\n",
    "# Build a query\n",
    "query = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .select_level(850)\n",
    "    .select_year(2020, 2021, 2022)\n",
    "    .year_mean()\n",
    "    .field_mean()\n",
    ")\n",
    "\n",
    "# 1. Get the raw CDO command\n",
    "print(\"üîç Generated CDO Command:\")\n",
    "print(\"=\" * 70)\n",
    "print(query.get_command())\n",
    "\n",
    "# 2. Get human-readable explanation\n",
    "print(\"\\nüìã Human-Readable Explanation:\")\n",
    "print(\"=\" * 70)\n",
    "print(query.explain())\n",
    "\n",
    "# 3. List all operations in the pipeline\n",
    "print(\"\\nüîß Pipeline Operations:\")\n",
    "print(\"=\" * 70)\n",
    "for i, op in enumerate(query.get_operations(), 1):\n",
    "    print(f\"  {i}. {op.name}: {op.to_cdo_fragment()}\")\n",
    "\n",
    "print(\"\\nüí° This transparency helps you understand and debug complex queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb1a3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Query Branching\n",
    "\n",
    "**Create variations from a base query** using `.clone()`!\n",
    "\n",
    "This is powerful for comparative analyses - define the common processing once, then branch for different aggregations or regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrate query branching for comparative analyses.\n",
    "Create a base query, then clone it for different temporal aggregations.\n",
    "\"\"\"\n",
    "\n",
    "# Create a base query with common operations\n",
    "base = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .select_level(1000)  # Surface level\n",
    "    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)  # Europe\n",
    ")\n",
    "\n",
    "print(\"üå≥ Base Query Created\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Description: European surface temperature\")\n",
    "print(f\"Command: {base.get_command()}\")\n",
    "\n",
    "# Branch 1: Annual means\n",
    "print(\"\\nüìä Branch 1: Annual Means\")\n",
    "print(\"-\" * 70)\n",
    "annual_mean = base.clone().year_mean().field_mean().compute()\n",
    "print(f\"‚úÖ Computed annual means for {len(annual_mean.time)} years\")\n",
    "print(f\"   Values: {[f'{float(v):.2f}' for v in annual_mean.tas.values]} K\")\n",
    "\n",
    "# Branch 2: Monthly climatology\n",
    "print(\"\\nüìä Branch 2: Monthly Climatology\")\n",
    "print(\"-\" * 70)\n",
    "monthly_mean = base.clone().month_mean().field_mean().compute()\n",
    "print(\"‚úÖ Computed monthly climatology\")\n",
    "print(f\"   Shape: {dict(monthly_mean.dims)}\")\n",
    "print(f\"   Coldest month: {float(monthly_mean.tas.min().values):.2f} K\")\n",
    "print(f\"   Warmest month: {float(monthly_mean.tas.max().values):.2f} K\")\n",
    "\n",
    "# Branch 3: Seasonal means\n",
    "print(\"\\nüìä Branch 3: Seasonal Means\")\n",
    "print(\"-\" * 70)\n",
    "seasonal_mean = base.clone().season_mean().field_mean().compute()\n",
    "print(\"‚úÖ Computed seasonal means\")\n",
    "print(f\"   Shape: {dict(seasonal_mean.dims)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ Three different analyses from one base query!\")\n",
    "print(\"üí° This avoids code duplication and ensures consistency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0352724",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. F() Function: One-Liner Anomaly Calculations\n",
    "\n",
    "**The game-changer**: Calculate anomalies in a single line using the `F()` function!\n",
    "\n",
    "Inspired by Django's F-expressions, the `F()` function enables binary operations between datasets. This is particularly powerful for anomaly calculations.\n",
    "\n",
    "**Requirements**: CDO >= 1.9.8 (uses bracket notation internally)\n",
    "\n",
    "### How it Works\n",
    "\n",
    "```python\n",
    "# Traditional approach (multiple steps):\n",
    "data = cdo.select_var(\"sample.nc\", \"tas\")\n",
    "clim = cdo.time_mean(data)\n",
    "anomaly = cdo.sub(data, clim)\n",
    "\n",
    "# v1.0.0 approach (one line!):\n",
    "anomaly = cdo.query(\"sample.nc\").sub(F(\"climatology.nc\")).compute()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257faa2",
   "metadata": {},
   "source": [
    "### 4.1 Simple Anomaly Calculation\n",
    "\n",
    "Calculate anomalies from climatology in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a123af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ONE-LINER ANOMALY CALCULATION!\n",
    "Subtract climatology from data using F() function.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate anomaly: data - climatology\n",
    "anomaly = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .sub(F(\"climatology.nc\"))  # F() references another file\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Anomaly calculated in ONE LINE!\")\n",
    "print(\"\\nüìä Anomaly Statistics:\")\n",
    "print(f\"   Mean: {float(anomaly.tas.mean().values):>8.3f} K  (should be ~0)\")\n",
    "print(f\"   Std:  {float(anomaly.tas.std().values):>8.3f} K\")\n",
    "print(f\"   Min:  {float(anomaly.tas.min().values):>8.3f} K\")\n",
    "print(f\"   Max:  {float(anomaly.tas.max().values):>8.3f} K\")\n",
    "\n",
    "print(\"\\nüîç What happened under the hood:\")\n",
    "print(\"   CDO command: cdo -sub sample_data.nc climatology.nc\")\n",
    "print(\"\\nüí° With F(), complex operations are readable and concise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f22b2",
   "metadata": {},
   "source": [
    "### 4.2 Processing Both Sides Before Subtraction\n",
    "\n",
    "F() supports chaining! Process both datasets before the binary operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate temperature difference between pressure levels.\n",
    "Both sides are processed before subtraction.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate: (1000 hPa mean) - (500 hPa mean)\n",
    "temp_diff = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .select_level(1000)  # Left side: surface level\n",
    "    .time_mean()\n",
    "    .sub(\n",
    "        F(\"sample_data.nc\")  # Right side: upper level\n",
    "        .select_var(\"tas\")\n",
    "        .select_level(500)\n",
    "        .time_mean()\n",
    "    )\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Temperature Difference: 1000 hPa - 500 hPa\")\n",
    "print(\"\\nüìä Vertical Temperature Gradient:\")\n",
    "print(f\"   Mean difference: {float(temp_diff.tas.mean().values):>7.1f} K\")\n",
    "print(f\"   Min difference:  {float(temp_diff.tas.min().values):>7.1f} K\")\n",
    "print(f\"   Max difference:  {float(temp_diff.tas.max().values):>7.1f} K\")\n",
    "\n",
    "print(\"\\nüîç Generated CDO command with operator chaining:\")\n",
    "print(\"   cdo -sub -timmean -sellevel,1000 -selname,tas sample_data.nc \\\\\")\n",
    "print(\"            -timmean -sellevel,500 -selname,tas sample_data.nc\")\n",
    "print(\"\\nüí° F() handles complex nested operations in a single CDO command!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea16fb",
   "metadata": {},
   "source": [
    "### 4.3 Standardized Anomaly Calculation\n",
    "\n",
    "Chain multiple F() operations: `(data - mean) / std`\n",
    "\n",
    "**How it works**: Binary operations use CDO's operator chaining - all operations execute in a single command without temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate standardized anomaly: (data - mean) / std\n",
    "This is common in climate analysis for comparing different variables.\n",
    "\"\"\"\n",
    "\n",
    "# First, create standard deviation file\n",
    "print(\"üîÑ Creating standard deviation file...\\n\")\n",
    "std_dev = cdo.query(\"sample_data.nc\").select_var(\"tas\").time_std().compute()\n",
    "std_dev.to_netcdf(\"std_dev.nc\")\n",
    "print(\"‚úÖ Created std_dev.nc\\n\")\n",
    "\n",
    "# Calculate standardized anomaly: (data - mean) / std\n",
    "std_anomaly = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .sub(F(\"climatology.nc\"))  # Subtract mean\n",
    "    .div(F(\"std_dev.nc\"))  # Divide by standard deviation\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Standardized Anomaly Calculated!\")\n",
    "print(\"\\nüìä Standardized Anomaly Statistics:\")\n",
    "print(f\"   Mean: {float(std_anomaly.tas.mean().values):>8.3f}  (should be ~0)\")\n",
    "print(f\"   Std:  {float(std_anomaly.tas.std().values):>8.3f}  (should be ~1)\")\n",
    "print(f\"   Min:  {float(std_anomaly.tas.min().values):>8.3f}\")\n",
    "print(f\"   Max:  {float(std_anomaly.tas.max().values):>8.3f}\")\n",
    "\n",
    "print(\"\\nüí° Standardized anomalies allow fair comparison across variables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9666f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Selection Operators\n",
    "\n",
    "**18 selection operators** for filtering data by:\n",
    "- Variables, levels, time dimensions\n",
    "- Spatial regions\n",
    "- Masks and conditions\n",
    "\n",
    "All selections use **named parameters** for clarity and type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ad815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable selection\n",
    "print(\"üìä Selection Operators Demo\\n\")\n",
    "\n",
    "# 1. Select variables\n",
    "print(\"1Ô∏è‚É£ Select variables:\")\n",
    "ds = cdo.query(\"sample_data.nc\").select_var(\"tas\", \"pr\").compute()\n",
    "print(f\"   Variables: {list(ds.data_vars)}\")\n",
    "\n",
    "# 2. Select vertical levels\n",
    "print(\"\\n2Ô∏è‚É£ Select vertical levels:\")\n",
    "ds = cdo.query(\"sample_data.nc\").select_var(\"tas\").select_level(850, 500).compute()\n",
    "print(f\"   Levels: {list(ds.level.values)}\")\n",
    "\n",
    "# 3. Select years\n",
    "print(\"\\n3Ô∏è‚É£ Select years:\")\n",
    "ds = cdo.query(\"sample_data.nc\").select_year(2020, 2021).compute()\n",
    "print(f\"   Time range: {ds.time[0].values} to {ds.time[-1].values}\")\n",
    "\n",
    "# 4. Select months\n",
    "print(\"\\n4Ô∏è‚É£ Select specific months (JJA):\")\n",
    "ds = cdo.query(\"sample_data.nc\").select_month(6, 7, 8).compute()\n",
    "print(f\"   Timesteps: {len(ds.time)} (summer months only)\")\n",
    "\n",
    "# 5. Select seasons\n",
    "print(\"\\n5Ô∏è‚É£ Select seasons:\")\n",
    "ds = cdo.query(\"sample_data.nc\").select_season(\"DJF\", \"JJA\").compute()\n",
    "print(f\"   Timesteps: {len(ds.time)} (winter and summer)\")\n",
    "\n",
    "# 6. Select spatial region\n",
    "print(\"\\n6Ô∏è‚É£ Select spatial region (Europe):\")\n",
    "ds = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)\n",
    "    .compute()\n",
    ")\n",
    "print(\n",
    "    f\"   Lat range: {float(ds.lat.min().values):.1f} to {float(ds.lat.max().values):.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   Lon range: {float(ds.lon.min().values):.1f} to {float(ds.lon.max().values):.1f}\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ All selection operators working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e997e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Statistical Operators\n",
    "\n",
    "**50+ statistical operators** across multiple dimensions:\n",
    "\n",
    "- **Temporal**: time, year, month, day, hour, season statistics\n",
    "- **Spatial**: field, zonal, meridional statistics  \n",
    "- **Vertical**: vertical integration, averaging\n",
    "- **Running**: moving window statistics\n",
    "- **Percentiles**: temporal and spatial percentiles\n",
    "\n",
    "All statistics support: mean, sum, min, max, std, var, range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Statistical Operators Demo\\n\")\n",
    "\n",
    "# Base query\n",
    "base = cdo.query(\"sample_data.nc\").select_var(\"tas\").select_level(1000)\n",
    "\n",
    "# 1. Time statistics\n",
    "print(\"1Ô∏è‚É£ Time statistics:\")\n",
    "time_mean = base.clone().time_mean().compute()\n",
    "print(f\"   Time mean shape: {time_mean.dims}\")\n",
    "time_std = base.clone().time_std().compute()\n",
    "print(f\"   Time std shape: {time_std.dims}\")\n",
    "\n",
    "# 2. Year statistics\n",
    "print(\"\\n2Ô∏è‚É£ Year statistics:\")\n",
    "year_mean = base.clone().year_mean().compute()\n",
    "print(f\"   Annual means: {len(year_mean.time)} years\")\n",
    "\n",
    "# 3. Month statistics\n",
    "print(\"\\n3Ô∏è‚É£ Monthly climatology:\")\n",
    "month_mean = base.clone().month_mean().compute()\n",
    "print(f\"   Monthly means: {len(month_mean.time)} months\")\n",
    "\n",
    "# 4. Season statistics\n",
    "print(\"\\n4Ô∏è‚É£ Seasonal statistics:\")\n",
    "season_mean = base.clone().season_mean().compute()\n",
    "print(f\"   Seasonal shape: {season_mean.dims}\")\n",
    "\n",
    "# 5. Field (spatial) statistics\n",
    "print(\"\\n5Ô∏è‚É£ Field statistics:\")\n",
    "field_mean = base.clone().field_mean().compute()\n",
    "print(f\"   Field mean shape: {field_mean.dims} (spatial dims removed)\")\n",
    "print(f\"   Global mean temp: {float(field_mean.tas.mean().values):.2f} K\")\n",
    "\n",
    "# 6. Zonal mean\n",
    "print(\"\\n6Ô∏è‚É£ Zonal mean:\")\n",
    "zonal = base.clone().zonal_mean().compute()\n",
    "print(f\"   Zonal mean shape: {zonal.dims}\")\n",
    "\n",
    "# 7. Vertical statistics\n",
    "print(\"\\n7Ô∏è‚É£ Vertical integration:\")\n",
    "vert_int = cdo.query(\"sample_data.nc\").select_var(\"tas\").vert_int().compute()\n",
    "print(f\"   Vertical integral shape: {vert_int.dims}\")\n",
    "\n",
    "print(\"\\n‚úÖ All statistical operators working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5bc1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Arithmetic Operators\n",
    "\n",
    "**30+ arithmetic operators** for mathematical operations:\n",
    "\n",
    "- **Constants**: Add, subtract, multiply, divide by constants\n",
    "- **Binary operations**: Between datasets using F()\n",
    "- **Math functions**: abs, sqrt, exp, ln, log10, trigonometric\n",
    "- **Masking**: Conditional operations with ifthen/ifthenelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¢ Arithmetic Operators Demo\\n\")\n",
    "\n",
    "base = cdo.query(\"sample_data.nc\").select_var(\"tas\")\n",
    "\n",
    "# 1. Constant arithmetic\n",
    "print(\"1Ô∏è‚É£ Convert Kelvin to Celsius:\")\n",
    "celsius = base.clone().sub_constant(273.15).compute()\n",
    "print(f\"   Original: {float(base.clone().compute().tas.mean().values):.2f} K\")\n",
    "print(f\"   Celsius:  {float(celsius.tas.mean().values):.2f} ¬∞C\")\n",
    "\n",
    "# 2. Multiply by constant\n",
    "print(\"\\n2Ô∏è‚É£ Scale by factor:\")\n",
    "scaled = base.clone().mul_constant(1.1).compute()\n",
    "print(\"   Scaled by 10%\")\n",
    "\n",
    "# 3. Math functions\n",
    "print(\"\\n3Ô∏è‚É£ Math functions:\")\n",
    "\n",
    "# Absolute value\n",
    "anomaly_abs = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .sub(F(\"climatology.nc\"))\n",
    "    .abs()\n",
    "    .compute()\n",
    ")\n",
    "print(f\"   Absolute anomaly mean: {float(anomaly_abs.tas.mean().values):.2f} K\")\n",
    "\n",
    "# Square\n",
    "squared = cdo.query(\"sample_data.nc\").select_var(\"pr\").sqr().compute()\n",
    "print(f\"   Squared precipitation shape: {squared.dims}\")\n",
    "\n",
    "print(\"\\n‚úÖ Arithmetic operators working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf6ffd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Interpolation and Regridding\n",
    "\n",
    "**9 interpolation operators** for spatial transformations:\n",
    "\n",
    "- **Horizontal**: bilinear, bicubic, nearest-neighbor, distance-weighted, conservative\n",
    "- **Vertical**: level interpolation, model-to-pressure level conversion\n",
    "- **Grid specifications**: Use `GridSpec` class for target grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710eedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üó∫Ô∏è  Interpolation and Regridding Demo\\n\")\n",
    "\n",
    "# Original grid\n",
    "original = cdo.query(\"sample_data.nc\").select_var(\"tas\").compute()\n",
    "print(f\"Original grid: {len(original.lon)} √ó {len(original.lat)}\")\n",
    "\n",
    "# 1. Bilinear interpolation to coarser grid\n",
    "print(\"\\n1Ô∏è‚É£ Bilinear interpolation to 5¬∞ √ó 5¬∞:\")\n",
    "grid_5deg = GridSpec(\n",
    "    gridtype=\"lonlat\",\n",
    "    xsize=72,  # 360/5\n",
    "    ysize=36,  # 180/5\n",
    "    xfirst=0,\n",
    "    xinc=5,\n",
    "    yfirst=-87.5,\n",
    "    yinc=5,\n",
    ")\n",
    "\n",
    "# Save grid spec to file\n",
    "with open(\"grid_5deg.txt\", \"w\") as f:\n",
    "    f.write(grid_5deg.to_cdo_string())\n",
    "\n",
    "regridded = (\n",
    "    cdo.query(\"sample_data.nc\").select_var(\"tas\").remap_bil(\"grid_5deg.txt\").compute()\n",
    ")\n",
    "print(f\"   Regridded: {len(regridded.lon)} √ó {len(regridded.lat)}\")\n",
    "\n",
    "# 2. Conservative remapping (better for flux variables)\n",
    "print(\"\\n2Ô∏è‚É£ Conservative remapping for precipitation:\")\n",
    "pr_regrid = (\n",
    "    cdo.query(\"sample_data.nc\").select_var(\"pr\").remap_con(\"grid_5deg.txt\").compute()\n",
    ")\n",
    "print(f\"   Precipitation regridded: {pr_regrid.dims}\")\n",
    "print(f\"   Total precipitation conserved: {float(pr_regrid.pr.sum().values):.1f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Interpolation operators working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea907b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Structured Info Commands\n",
    "\n",
    "**Type-safe result objects** instead of strings!\n",
    "\n",
    "Get file information as **Python dataclasses** with:\n",
    "- Full type hints and IDE autocompletion\n",
    "- Helper methods and properties\n",
    "- No manual string parsing\n",
    "\n",
    "Available info commands:\n",
    "- `sinfo()` - Complete file information\n",
    "- `griddes()` - Grid descriptions\n",
    "- `zaxisdes()` - Vertical coordinate info\n",
    "- `vlist()` - Variable list\n",
    "- `partab()` - Parameter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6077605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ÑπÔ∏è  Structured Info Commands Demo\\n\")\n",
    "\n",
    "# 1. sinfo - Complete file information\n",
    "print(\"1Ô∏è‚É£ File Information (sinfo):\")\n",
    "info = cdo.sinfo(\"sample_data.nc\")\n",
    "print(f\"   Type: {type(info).__name__}\")\n",
    "print(f\"   File format: {info.file_format}\")\n",
    "print(f\"   Number of variables: {info.nvar}\")\n",
    "print(f\"   Variable names: {info.var_names}\")\n",
    "print(f\"   Time range: {info.time_range}\")\n",
    "\n",
    "print(\"\\n   Variables details:\")\n",
    "for var in info.variables:\n",
    "    if var.name:\n",
    "        print(f\"     - {var.name}: {var.longname} [{var.units}]\")\n",
    "\n",
    "# 2. griddes - Grid information\n",
    "print(\"\\n2Ô∏è‚É£ Grid Information (griddes):\")\n",
    "grid = cdo.griddes(\"sample_data.nc\")\n",
    "print(f\"   Type: {type(grid).__name__}\")\n",
    "print(f\"   Number of grids: {len(grid.grids)}\")\n",
    "if grid.grids:\n",
    "    g = grid.grids[0]\n",
    "    print(f\"   Grid type: {g.gridtype}\")\n",
    "    print(f\"   Size: {g.xsize} √ó {g.ysize}\")\n",
    "    if hasattr(g, \"xinc\") and g.xinc:\n",
    "        print(f\"   Resolution: {g.xinc}¬∞ √ó {g.yinc}¬∞\")\n",
    "\n",
    "# 3. vlist - Variable list\n",
    "print(\"\\n3Ô∏è‚É£ Variable List (vlist):\")\n",
    "vlist = cdo.vlist(\"sample_data.nc\")\n",
    "print(f\"   Type: {type(vlist).__name__}\")\n",
    "print(\"   Variables:\")\n",
    "for var in vlist.variables:\n",
    "    print(f\"     - {var.name}: Code {var.code}\")\n",
    "\n",
    "# 4. partab - Parameter table\n",
    "print(\"\\n4Ô∏è‚É£ Parameter Table (partab):\")\n",
    "partab = cdo.partab(\"sample_data.nc\")\n",
    "print(f\"   Type: {type(partab).__name__}\")\n",
    "print(f\"   Number of parameters: {len(partab.parameters)}\")\n",
    "for param in partab.parameters[:3]:  # Show first 3\n",
    "    print(f\"     - Code {param.code}: {param.name} [{param.units}]\")\n",
    "\n",
    "print(\"\\n‚úÖ All structured info commands working!\")\n",
    "print(\"\\nüí° Benefits:\")\n",
    "print(\"   - Type-safe access to all fields\")\n",
    "print(\"   - IDE autocompletion\")\n",
    "print(\"   - No string parsing required\")\n",
    "print(\"   - Helper methods (e.g., info.var_names, info.time_range)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1982b2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Advanced Query Methods\n",
    "\n",
    "**Django-inspired shortcuts** for common query operations:\n",
    "\n",
    "- `.first()` - Get first timestep\n",
    "- `.last()` - Get last timestep  \n",
    "- `.count()` - Count timesteps (returns int)\n",
    "- `.exists()` - Check if data exists (returns bool)\n",
    "- `.values(*vars)` - Alias for select_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Advanced Query Methods Demo\\n\")\n",
    "\n",
    "base_query = cdo.query(\"sample_data.nc\").select_var(\"tas\")\n",
    "\n",
    "# 1. first() - Get first timestep\n",
    "print(\"1Ô∏è‚É£ Get first timestep:\")\n",
    "first = base_query.clone().first()\n",
    "print(f\"   Shape: {first.dims}\")\n",
    "print(f\"   Time: {first.time.values}\")\n",
    "\n",
    "# 2. last() - Get last timestep\n",
    "print(\"\\n2Ô∏è‚É£ Get last timestep:\")\n",
    "last = base_query.clone().last()\n",
    "print(f\"   Shape: {last.dims}\")\n",
    "print(f\"   Time: {last.time.values}\")\n",
    "\n",
    "# 3. count() - Get number of timesteps\n",
    "print(\"\\n3Ô∏è‚É£ Count timesteps:\")\n",
    "n_timesteps = base_query.clone().count()\n",
    "print(f\"   Number of timesteps: {n_timesteps}\")\n",
    "print(f\"   Type: {type(n_timesteps)}\")\n",
    "\n",
    "# 4. exists() - Check if data exists\n",
    "print(\"\\n4Ô∏è‚É£ Check if data exists:\")\n",
    "exists = base_query.clone().exists()\n",
    "print(f\"   Data exists: {exists}\")\n",
    "print(f\"   Type: {type(exists)}\")\n",
    "\n",
    "# 5. values() - Alias for select_var()\n",
    "print(\"\\n5Ô∏è‚É£ Select variables with .values():\")\n",
    "ds = cdo.query(\"sample_data.nc\").values(\"tas\", \"pr\").compute()\n",
    "print(f\"   Variables: {list(ds.data_vars)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Advanced query methods working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e2d05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. File Operations\n",
    "\n",
    "**Merge, split, and manage** NetCDF files:\n",
    "\n",
    "- **Merge**: Combine files by time or variables\n",
    "- **Split**: Separate by year, month, day, hour, variable, level\n",
    "- **Concatenate**: Join multiple files\n",
    "- **Copy**: Duplicate with optional format conversion\n",
    "\n",
    "All operations return xarray Datasets for immediate use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÅ File Operations Demo\\n\")\n",
    "\n",
    "# 1. Split by year\n",
    "print(\"1Ô∏è‚É£ Split by year:\")\n",
    "cdo.splityear(\"sample_data.nc\", prefix=\"year_\")\n",
    "print(\"   Created: year_2020.nc, year_2021.nc, year_2022.nc\")\n",
    "\n",
    "# 2. Merge time series\n",
    "print(\"\\n2Ô∏è‚É£ Merge time series:\")\n",
    "merged = cdo.mergetime(\"year_2020.nc\", \"year_2021.nc\", \"year_2022.nc\")\n",
    "print(f\"   Merged shape: {merged.dims}\")\n",
    "print(f\"   Time range: {merged.time[0].values} to {merged.time[-1].values}\")\n",
    "\n",
    "# 3. Split by variable\n",
    "print(\"\\n3Ô∏è‚É£ Split by variable:\")\n",
    "cdo.splitname(\"sample_data.nc\", prefix=\"var_\")\n",
    "print(\"   Created: var_tas.nc, var_pr.nc\")\n",
    "\n",
    "# 4. Merge variables\n",
    "print(\"\\n4Ô∏è‚É£ Merge variables:\")\n",
    "merged_vars = cdo.merge(\"var_tas.nc\", \"var_pr.nc\")\n",
    "print(f\"   Variables: {list(merged_vars.data_vars)}\")\n",
    "\n",
    "print(\"\\n‚úÖ File operations working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bfaa4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Real-World Example: Complete Analysis Workflow\n",
    "\n",
    "**Putting it all together**: A complete climate analysis workflow.\n",
    "\n",
    "This example demonstrates a realistic analysis combining:\n",
    "- Regional selection (Europe)\n",
    "- Temporal filtering (winter season)\n",
    "- Multiple aggregations (annual, spatial, climatology)\n",
    "- Anomaly calculations with F()\n",
    "- Variability analysis\n",
    "\n",
    "**Goal**: Analyze European winter temperature trends and variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3343d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåç Real-World Analysis: European Winter Temperature Trends\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Extract European winter (DJF) surface temperature\n",
    "print(\"\\nüìç Step 1: Extract European winter temperature\")\n",
    "europe_winter = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .select_level(1000)\n",
    "    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)\n",
    "    .select_season(\"DJF\")\n",
    ")\n",
    "\n",
    "print(f\"   Command: {europe_winter.get_command()[:80]}...\")\n",
    "\n",
    "# Step 2: Calculate annual winter means\n",
    "print(\"\\nüìä Step 2: Calculate annual winter means\")\n",
    "annual_winter = europe_winter.clone().year_mean().field_mean().compute()\n",
    "print(f\"   Years: {len(annual_winter.time)}\")\n",
    "print(\"   Mean temperatures:\")\n",
    "for i, temp in enumerate(annual_winter.tas.values):\n",
    "    year = 2020 + i\n",
    "    print(f\"     {year}: {float(temp):.2f} K ({float(temp) - 273.15:.2f} ¬∞C)\")\n",
    "\n",
    "# Step 3: Calculate spatial pattern\n",
    "print(\"\\nüó∫Ô∏è  Step 3: Calculate winter climatology (spatial pattern)\")\n",
    "winter_clim = europe_winter.clone().time_mean().compute()\n",
    "print(f\"   Climatology shape: {winter_clim.dims}\")\n",
    "print(f\"   Spatial mean: {float(winter_clim.tas.mean().values):.2f} K\")\n",
    "print(f\"   Spatial std:  {float(winter_clim.tas.std().values):.2f} K\")\n",
    "\n",
    "# Step 4: Calculate anomalies from climatology\n",
    "print(\"\\nüìâ Step 4: Calculate winter anomalies\")\n",
    "winter_clim.to_netcdf(\"europe_winter_clim.nc\")\n",
    "\n",
    "anomalies = (\n",
    "    europe_winter.clone()\n",
    "    .sub(F(\"europe_winter_clim.nc\"))\n",
    "    .year_mean()\n",
    "    .field_mean()\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"   Anomalies (relative to 3-year mean):\")\n",
    "for i, anom in enumerate(anomalies.tas.values):\n",
    "    year = 2020 + i\n",
    "    sign = \"+\" if float(anom) >= 0 else \"\"\n",
    "    print(f\"     {year}: {sign}{float(anom):.3f} K\")\n",
    "\n",
    "# Step 5: Calculate variability\n",
    "print(\"\\nüìä Step 5: Analyze spatial variability\")\n",
    "winter_std = europe_winter.clone().time_std().compute()\n",
    "print(f\"   Temporal std (spatial map): {winter_std.dims}\")\n",
    "print(f\"   Mean variability: {float(winter_std.tas.mean().values):.2f} K\")\n",
    "print(f\"   Max variability:  {float(winter_std.tas.max().values):.2f} K\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Complete analysis workflow executed!\")\n",
    "print(\"\\nüí° This entire analysis used:\")\n",
    "print(\"   - Query chaining for readable pipelines\")\n",
    "print(\"   - Query branching for multiple analyses\")\n",
    "print(\"   - F() function for anomaly calculation\")\n",
    "print(\"   - Lazy evaluation with .compute()\")\n",
    "print(\"\\nüéØ Total lines of code: ~15 (vs. 50+ with traditional approach!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f3d20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Comparison: v0.x vs v1.0.0\n",
    "\n",
    "**Side-by-side comparison** showing the improvements in v1.0.0.\n",
    "\n",
    "### What Changed?\n",
    "\n",
    "**v0.x**: String-based CDO commands\n",
    "- Hard to read and maintain\n",
    "- No type checking\n",
    "- Order-dependent parameters\n",
    "- Can't inspect before execution\n",
    "\n",
    "**v1.0.0**: Django ORM-style query API  \n",
    "- Self-documenting code\n",
    "- Full type safety\n",
    "- Named parameters (order-independent)\n",
    "- Query introspection\n",
    "- Query branching and composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öñÔ∏è  v0.x vs v1.0.0 Comparison\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìù Task: Calculate European winter mean temperature\\n\")\n",
    "\n",
    "print(\"‚ùå v0.x approach (string-based):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"from python_cdo_wrapper import cdo\")\n",
    "print(\"\")\n",
    "print(\n",
    "    'ds, log = cdo(\"-fldmean -yearmean -selseason,DJF -sellonlatbox,-10,40,35,70 -sellevel,1000 -selname,tas input.nc\")'\n",
    ")\n",
    "print(\"\")\n",
    "print(\"Issues:\")\n",
    "print(\"  - Hard to read (one long string)\")\n",
    "print(\"  - Parameter order matters\")\n",
    "print(\"  - No type checking\")\n",
    "print(\"  - No IDE autocompletion\")\n",
    "print(\"  - Can't inspect before execution\")\n",
    "\n",
    "print(\"\\n‚úÖ v1.0.0 approach (query API):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"from python_cdo_wrapper import CDO\")\n",
    "print(\"\")\n",
    "print(\"cdo = CDO()\")\n",
    "print(\"\")\n",
    "print(\"query = (\")\n",
    "print(\"    cdo.query('input.nc')\")\n",
    "print(\"    .select_var('tas')\")\n",
    "print(\"    .select_level(1000)\")\n",
    "print(\"    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)\")\n",
    "print(\"    .select_season('DJF')\")\n",
    "print(\"    .year_mean()\")\n",
    "print(\"    .field_mean()\")\n",
    "print(\")\")\n",
    "print(\"\")\n",
    "print(\"print(query.get_command())  # Inspect first!\")\n",
    "print(\"ds = query.compute()\")\n",
    "print(\"\")\n",
    "print(\"Benefits:\")\n",
    "print(\"  ‚úÖ Self-documenting code\")\n",
    "print(\"  ‚úÖ Named parameters (order-independent)\")\n",
    "print(\"  ‚úÖ Full type checking\")\n",
    "print(\"  ‚úÖ IDE autocompletion\")\n",
    "print(\"  ‚úÖ Inspect before execution\")\n",
    "print(\"  ‚úÖ Clone and branch for variations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Actual execution to prove it works\n",
    "result = (\n",
    "    cdo.query(\"sample_data.nc\")\n",
    "    .select_var(\"tas\")\n",
    "    .select_level(1000)\n",
    "    .select_region(lon1=-10, lon2=40, lat1=35, lat2=70)\n",
    "    .select_season(\"DJF\")\n",
    "    .year_mean()\n",
    "    .field_mean()\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ v1.0.0 query executed successfully!\")\n",
    "print(f\"   Result shape: {result.dims}\")\n",
    "print(f\"   Mean temperature: {float(result.tas.mean().values):.2f} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47dee5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14. Cleanup\n",
    "\n",
    "Clean up temporary files created during the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clean up temporary files\n",
    "temp_files = [\n",
    "    \"sample_data.nc\",\n",
    "    \"climatology.nc\",\n",
    "    \"std_dev.nc\",\n",
    "    \"europe_winter_clim.nc\",\n",
    "    \"grid_5deg.txt\",\n",
    "    \"year_2020.nc\",\n",
    "    \"year_2021.nc\",\n",
    "    \"year_2022.nc\",\n",
    "    \"var_tas.nc\",\n",
    "    \"var_pr.nc\",\n",
    "]\n",
    "\n",
    "print(\"üßπ Cleaning up temporary files...\\n\")\n",
    "for f in temp_files:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"   ‚úÖ Removed {f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea433f89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated **all major v1.0.0 features** of python-cdo-wrapper!\n",
    "\n",
    "### ‚úÖ Core Features Covered\n",
    "\n",
    "1. **Django ORM-style Query API** - Lazy, chainable operations\n",
    "2. **Query Introspection** - `.get_command()`, `.explain()`, `.get_operations()`\n",
    "3. **Query Branching** - `.clone()` for multiple analyses from one base\n",
    "4. **F() Function** - One-liner anomaly calculations (Django F-expression pattern)\n",
    "5. **Structured Results** - Typed dataclasses for info commands\n",
    "\n",
    "### ‚úÖ Operator Categories (150+ total)\n",
    "\n",
    "- **Selection** (18 operators) - Variables, levels, time, space, regions\n",
    "- **Statistics** (50+ operators) - Time, field, vertical, running, percentiles\n",
    "- **Arithmetic** (30+ operators) - Constants, binary ops, math functions\n",
    "- **Interpolation** (9 operators) - Horizontal and vertical regridding\n",
    "- **Advanced Methods** - `.first()`, `.last()`, `.count()`, `.exists()`, `.values()`\n",
    "- **File Operations** - Merge, split, concatenate, copy\n",
    "\n",
    "### üéØ Key Benefits\n",
    "\n",
    "- **Readable**: Self-documenting, chainable code\n",
    "- **Type-safe**: Full IDE autocompletion and type checking\n",
    "- **Flexible**: Query branching, cloning, and templates\n",
    "- **Powerful**: One-liner anomaly calculations with F()\n",
    "- **Inspectable**: See commands before execution\n",
    "- **Backward compatible**: v0.x string-based API still works!\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "- üìñ Read the [Migration Guide](../MIGRATION_GUIDE.md) for upgrading from v0.x\n",
    "- üìñ Check the [README](../README.md) for complete API reference\n",
    "- üîç Explore [Real-World Examples](../README.md#real-world-climate-science-examples)\n",
    "- üêõ Report issues on [GitHub](https://github.com/NarenKarthikBM/python-cdo-wrapper)\n",
    "\n",
    "### üôè Acknowledgments\n",
    "\n",
    "python-cdo-wrapper v1.0.0 is inspired by:\n",
    "- **Django ORM** - QuerySet pattern and lazy evaluation\n",
    "- **Django F-expressions** - Binary operations with F()\n",
    "- **xarray** - NetCDF data structures\n",
    "- **CDO** - Climate Data Operators (the engine underneath)\n",
    "\n",
    "---\n",
    "\n",
    "**python-cdo-wrapper v1.0.0** - Making climate data processing more Pythonic! üéâ\n",
    "\n",
    "Built with ‚ù§Ô∏è for the climate science community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCC",
   "language": "python",
   "name": "gcc-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
